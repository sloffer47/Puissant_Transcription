{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNyXgNfJSUQxlbcsJ4axVIq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sloffer47/Puissant_Transcription/blob/main/Transcriber.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 940
        },
        "collapsed": true,
        "id": "2MC26EqLIbrr",
        "outputId": "9e9e4967-2da1-4ec2-dfc6-63b45f1a7817"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ Installation des d√©pendances...\n",
            "‚úÖ Installation termin√©e!\n",
            "üéÆ GPU disponible: True\n",
            "üí™ GPU: Tesla T4\n",
            "‚è≥ Chargement du mod√®le Whisper large-v3...\n",
            "‚úÖ Mod√®le charg√©!\n",
            "üé® Cr√©ation de l'interface...\n",
            "\n",
            "==================================================\n",
            "üöÄ LANCEMENT DE L'APPLICATION\n",
            "==================================================\n",
            "\n",
            "üì± L'interface va s'ouvrir ci-dessous...\n",
            "üé§ Upload ton fichier audio et clique sur Submit!\n",
            "==================================================\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://91aef7f9b9252a967e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://91aef7f9b9252a967e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üé§ Transcription en cours...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12033/12033 [00:41<00:00, 290.20frames/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Transcription termin√©e! 40 segments\n"
          ]
        }
      ],
      "source": [
        "# TRANSCRIPTION AUDIO ULTRA-RAPIDE SUR GOOGLE COLAB\n",
        "# Copiez ce code dans un nouveau notebook Google Colab\n",
        "# https://colab.research.google.com/\n",
        "\n",
        "# ========================================\n",
        "# √âTAPE 1 : Installation (1-2 minutes)\n",
        "# ========================================\n",
        "print(\"üì¶ Installation des d√©pendances...\")\n",
        "!pip install -q openai-whisper\n",
        "!pip install -q gradio\n",
        "\n",
        "print(\"‚úÖ Installation termin√©e!\")\n",
        "\n",
        "# ========================================\n",
        "# √âTAPE 2 : Code de transcription\n",
        "# ========================================\n",
        "import whisper\n",
        "import gradio as gr\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "print(f\"üéÆ GPU disponible: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"üí™ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# Charger le mod√®le (large-v3 avec GPU gratuit!)\n",
        "print(\"‚è≥ Chargement du mod√®le Whisper large-v3...\")\n",
        "model = whisper.load_model(\"large\")\n",
        "print(\"‚úÖ Mod√®le charg√©!\")\n",
        "\n",
        "def transcribe_audio(audio_file, language=\"fr\"):\n",
        "    \"\"\"\n",
        "    Transcrit un fichier audio\n",
        "\n",
        "    Args:\n",
        "        audio_file: Chemin du fichier audio\n",
        "        language: Langue (fr, en, es, etc.)\n",
        "\n",
        "    Returns:\n",
        "        Texte transcrit\n",
        "    \"\"\"\n",
        "    if audio_file is None:\n",
        "        return \"‚ùå Veuillez uploader un fichier audio\"\n",
        "\n",
        "    print(f\"üé§ Transcription en cours...\")\n",
        "\n",
        "    try:\n",
        "        # Transcription\n",
        "        result = model.transcribe(\n",
        "            audio_file,\n",
        "            language=language,\n",
        "            task=\"transcribe\",\n",
        "            fp16=True,  # Utilise GPU\n",
        "            verbose=False,\n",
        "            beam_size=5,\n",
        "            best_of=5,\n",
        "            temperature=0.0\n",
        "        )\n",
        "\n",
        "        # Formatage du r√©sultat\n",
        "        transcript = \"\"\n",
        "        for segment in result[\"segments\"]:\n",
        "            start = format_timestamp(segment[\"start\"])\n",
        "            end = format_timestamp(segment[\"end\"])\n",
        "            text = segment[\"text\"].strip()\n",
        "            transcript += f\"[{start} ‚Üí {end}] {text}\\n\\n\"\n",
        "\n",
        "        print(f\"‚úÖ Transcription termin√©e! {len(result['segments'])} segments\")\n",
        "        return transcript\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Erreur: {str(e)}\"\n",
        "\n",
        "def format_timestamp(seconds):\n",
        "    \"\"\"Convertit secondes en HH:MM:SS\"\"\"\n",
        "    h = int(seconds // 3600)\n",
        "    m = int((seconds % 3600) // 60)\n",
        "    s = int(seconds % 60)\n",
        "    return f\"{h:02d}:{m:02d}:{s:02d}\"\n",
        "\n",
        "# ========================================\n",
        "# √âTAPE 3 : Interface Gradio\n",
        "# ========================================\n",
        "print(\"üé® Cr√©ation de l'interface...\")\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=transcribe_audio,\n",
        "    inputs=[\n",
        "        gr.Audio(type=\"filepath\", label=\"üìÅ Upload ton fichier audio (MP3, WAV, etc.)\"),\n",
        "        gr.Dropdown(\n",
        "            choices=[\"fr\", \"en\", \"es\", \"de\", \"it\", \"pt\"],\n",
        "            value=\"fr\",\n",
        "            label=\"üåç Langue\"\n",
        "        )\n",
        "    ],\n",
        "    outputs=gr.Textbox(\n",
        "        label=\"üìù Transcrip\",\n",
        "        lines=20,\n",
        "        show_copy_button=True\n",
        "    ),\n",
        "    title=\"üéôÔ∏è Transcripteur Audio Ultra-Puissant (GPU Gratuit)\",\n",
        "    description=\"\"\"\n",
        "    ### ‚ö° Transcription ultra-rapide avec Whisper large-v3 sur GPU NVIDIA gratuit!\n",
        "\n",
        "    **üìã Formats support√©s:** MP3, WAV, M4A, FLAC, OGG, WMA\n",
        "    **‚è±Ô∏è Vitesse:** ~5-10x plus rapide qu'un CPU normal\n",
        "    **üíæ Limite:** 2 Go par fichier (largement suffisant!)\n",
        "\n",
        "    **üí° Astuce:** Le GPU est d√©j√† activ√© si tu vois \"GPU: Tesla T4\" ci-dessus\n",
        "    \"\"\",\n",
        "    flagging_mode=\"never\",\n",
        "    cache_examples=False\n",
        ")\n",
        "\n",
        "# ========================================\n",
        "# √âTAPE 4 : Lancement\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üöÄ LANCEMENT DE L'APPLICATION\")\n",
        "print(\"=\"*50)\n",
        "print(\"\\nüì± L'interface va s'ouvrir ci-dessous...\")\n",
        "print(\"üé§ Upload ton fichier audio et clique sur Submit!\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "demo.launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YS7yyQwNK7X4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}